{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "!pip install poetry\n",
    "```\n",
    "```bash\n",
    "!poetry install\n",
    "```\n",
    "### or\n",
    "\n",
    "```bash\n",
    "!pip install -r requirements.txt\n",
    "```"
   ],
   "id": "55f30313e285bde3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "MAX_TOKENS = 225\n",
    "TEMPERATURE = 0.7\n",
    "OPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\""
   ],
   "id": "848a76820df60c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting up the Pinecone client\n",
    "pinecone_client = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "spec = ServerlessSpec(cloud=os.getenv(\"PINECONE_CLOUD\"), region=os.getenv(\"PINECONE_REGION\"))\n",
    "index_name = os.getenv(\"PINECONE_INDEX_NAME\")"
   ],
   "id": "a43b9504f6bc401f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting up the OpenAI client\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ],
   "id": "3fd2f0124aaf7722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# chat history\n",
    "history = [\n",
    "    \"1: User: Hi there! How are you doing today? | Bot: Hello! I'm doing great, thank you! How can I assist you today?\",\n",
    "    \"2: User: What's the weather like today in New York? | Bot: Today in New York, it's sunny with a slight chance of rain.\",\n",
    "    \"3: User: Great! Do you have any good lunch suggestions? | Bot: Sure! How about trying a new salad recipe?\",\n",
    "    \"4: User: That sounds healthy. Any specific recipes? | Bot: You could try a quinoa salad with avocado and chicken.\",\n",
    "    \"5: User: Sounds delicious! I'll try it. What about dinner? | Bot: For dinner, you could make grilled salmon with vegetables.\",\n",
    "    \"6: User: Thanks for the suggestions! Any dessert ideas? | Bot: How about a simple fruit salad or yogurt with honey?\",\n",
    "    \"7: User: Perfect! Now, what are some good exercises? | Bot: You can try a mix of cardio and strength training exercises.\",\n",
    "    \"8: User: Any specific recommendations for cardio? | Bot: Running, cycling, and swimming are all excellent cardio exercises.\",\n",
    "    \"9: User: I'll start with running. Can you recommend any books? | Bot: 'Atomic Habits' by James Clear is a highly recommended book.\",\n",
    "    \"10: User: I'll check it out. What hobbies can I take up? | Bot: You could explore painting, hiking, or learning a new instrument.\",\n",
    "    \"11: User: Hiking sounds fun! Any specific trails? | Bot: There are great trails in the Rockies and the Appalachian Mountains.\",\n",
    "    \"12: User: I'll plan a trip. What about indoor activities? | Bot: Indoor activities like reading, cooking, or playing board games.\",\n",
    "    \"13: User: Nice! Any good board games? | Bot: Settlers of Catan and Ticket to Ride are both excellent choices.\",\n",
    "    \"14: User: I'll try them out. Any movie recommendations? | Bot: 'Inception' and 'The Matrix' are must-watch movies.\",\n",
    "    \"15: User: I love those movies! Any TV shows? | Bot: 'Breaking Bad' and 'Stranger Things' are very popular.\",\n",
    "    \"16: User: Great choices! What about podcasts? | Bot: 'How I Built This' and 'The Daily' are very informative.\",\n",
    "    \"17: User: Thanks! What are some good travel destinations? | Bot: Paris, Tokyo, and Bali are amazing travel spots.\",\n",
    "    \"18: User: I'll add them to my list. Any packing tips? | Bot: Roll your clothes to save space and use packing cubes.\",\n",
    "    \"19: User: That's helpful! What about travel insurance? | Bot: Always get travel insurance for safety and peace of mind.\",\n",
    "    \"20: User: Thanks for the tips! Any last advice? | Bot: Just enjoy your journey and make the most out of your experiences.\"\n",
    "]"
   ],
   "id": "89255345f4bfd640",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def initialize_pinecone_index(pinecone_index_name: Optional[str] = 'chat-history'):\n",
    "    \"\"\"\n",
    "    Initialize a Pinecone index for storing chat history.\n",
    "\n",
    "    Parameters:\n",
    "    pinecone_index_name (str, optional): The name of the Pinecone index. Defaults to 'chat-history'.\n",
    "\n",
    "    Returns:\n",
    "    pinecone.Index: The initialized Pinecone index, or None if the index does not exist.\n",
    "    \"\"\"\n",
    "    pinecone_index = None\n",
    "    try:\n",
    "\n",
    "        # Check if the index exists\n",
    "        if pinecone_index_name in pinecone_client.list_indexes().names():\n",
    "            pinecone_index = pinecone_client.Index(pinecone_index_name)\n",
    "        else:\n",
    "            print(f\"Index '{pinecone_index_name}' does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"Finished initializing Pinecone index.\")\n",
    "        return pinecone_index"
   ],
   "id": "271acb63096d5879",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_embeddings(message: str, model: Optional[str] = OPENAI_EMBEDDING_MODEL):\n",
    "    \"\"\"\n",
    "    Encode a message using OpenAI's text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    message (str): The message to be encoded.\n",
    "    model (str, optional): The model to be used for encoding. Defaults to OPENAI_EMBEDDING_MODEL.\n",
    "\n",
    "    Returns:\n",
    "    list: The encoded message.\n",
    "    \"\"\"\n",
    "    return openai_client.embeddings.create(input=message, model=model).data[0].embedding"
   ],
   "id": "84ca002fcd294055",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_embeddings_to_pinecone(chat_history: List[str],\n",
    "                               pinecone_index_name: Optional[str] = 'chat-history'):\n",
    "    \"\"\"\n",
    "    Add embeddings to Pinecone index.\n",
    "\n",
    "    Parameters:\n",
    "    chat_history (List[str]): The chat history to be added to the Pinecone index.\n",
    "    pinecone_index_name (str, optional): The name of the Pinecone index. Defaults to 'chat-history'.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified Pinecone index does not exist.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone index\n",
    "        pinecone_index = initialize_pinecone_index(pinecone_index_name)\n",
    "        if pinecone_index is None:\n",
    "            raise ValueError(f\"Index {pinecone_index_name} does not exist.\")\n",
    "\n",
    "        embeddings = []\n",
    "        for i, message in enumerate(chat_history):\n",
    "            embedding = get_embeddings(message)\n",
    "            embeddings.append({\n",
    "                'id': str(i + 1),\n",
    "                'values': embedding,\n",
    "                'metadata': {'text': message}\n",
    "            })\n",
    "        pinecone_index.upsert(vectors=embeddings)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"Finished processing embeddings.\")"
   ],
   "id": "6289d92ad6093c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "add_embeddings_to_pinecone(history, pinecone_client)",
   "id": "9542ad89820b5a0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def retrieve_relevant_history(query: str, top_k: Optional[int] = 2,\n",
    "                              pinecone_index_name: Optional[str] = 'chat-history'):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant message from the chat history based on the query.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query to be used for searching the chat history.\n",
    "    top_k (int, optional): The number of most relevant messages to retrieve. Defaults to 2.\n",
    "    pinecone_index_name (str, optional): The name of the Pinecone index. Defaults to 'chat-history'.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified Pinecone index does not exist.\n",
    "\n",
    "    Returns:\n",
    "    str: The most relevant message from the chat history.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone index\n",
    "        pinecone_index = initialize_pinecone_index(pinecone_index_name)\n",
    "        if pinecone_index is None:\n",
    "            raise ValueError(f\"Index {pinecone_index_name} does not exist.\")\n",
    "\n",
    "        # Get embeddings for the query\n",
    "        query_embedding = get_embeddings(query)\n",
    "\n",
    "        # Search for the most relevant message in the chat history\n",
    "        search_results = pinecone_index.query(vector=[query_embedding], top_k=top_k,\n",
    "                                              include_metadata=True)\n",
    "\n",
    "        # Get the most relevant message [top 2] based on the similarity score\n",
    "        relevant_message = '\\n'.join([r['metadata']['text'] for r in search_results['matches']])\n",
    "\n",
    "        return relevant_message\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"Finished retrieving relevant history.\")"
   ],
   "id": "ea39ff6a687e2684"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_system_prompt(query: str):\n",
    "    \"\"\"\n",
    "    Prepare the prompt for the OpenAI chat completion API.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user query.\n",
    "\n",
    "    Returns:\n",
    "    str: The prepared prompt.\n",
    "    str: The context referred to in the prompt.\n",
    "    \"\"\"\n",
    "    # Retrieve the most relevant chat history based on the user's query\n",
    "    context = retrieve_relevant_history(query)\n",
    "\n",
    "    # Prepare the prompt template\n",
    "    prompt_template = (\"You are an AI assistant named Viamagus. \"\n",
    "                       \"Your role is to assist the user by answering their queries based on the context provided. \"\n",
    "                       \"You have access to the following context:\\n\"\n",
    "                       f\"{context}\\n\"\n",
    "                       )\n",
    "\n",
    "    return prompt_template, context"
   ],
   "id": "e8850ac38fdd795f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chat_with_openai(query: str):\n",
    "    \"\"\"\n",
    "    Chat with the OpenAI chat completion API.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user query.\n",
    "\n",
    "    Returns:\n",
    "    str: The response from the OpenAI chat completion API.\n",
    "    str: The context referred to in the response.\n",
    "    \"\"\"\n",
    "    system_prompt, context_referred = prepare_system_prompt(query)\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=TEMPERATURE\n",
    "    )\n",
    "    return res.choices[0].message.content, context_referred"
   ],
   "id": "20b0d2d8095f8715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def test_final_prompt():\n",
    "    query = \"Do you think it will help me stay fit?\"\n",
    "    response, context = chat_with_openai(query)\n",
    "    print(f\"Final Test Prompt: {query}\")\n",
    "    print(f\"Context Referred: {context}\")\n",
    "    print(f\"Final Test Prompt Response: {response}\")\n"
   ],
   "id": "b21db1bad46b4b35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_final_prompt()",
   "id": "fb05cec69bd9ff92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Open Soure Embedding Model",
   "id": "a49f2de9fc727756"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:02:41.803972Z",
     "start_time": "2024-06-19T19:02:29.674466Z"
    }
   },
   "cell_type": "code",
   "source": "from sentence_transformers import SentenceTransformer",
   "id": "88ebbb06654fce44",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:16:23.712783Z",
     "start_time": "2024-06-19T19:16:15.152086Z"
    }
   },
   "cell_type": "code",
   "source": "embedding_model = SentenceTransformer('BAAI/bge-large-en-v1.5')",
   "id": "4e79be560fc6ab66",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:34:18.231817Z",
     "start_time": "2024-06-19T19:34:18.210857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embeddings_open_source(messages: str, model: SentenceTransformer):\n",
    "    \"\"\"\n",
    "    Encode a list of messages using an open-source text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    messages (List[str]): The list of messages to be encoded.\n",
    "    model (SentenceTransformer): The open-source text-embedding model.\n",
    "\n",
    "    Returns:\n",
    "    list: The encoded messages.\n",
    "    \"\"\"\n",
    "    return model.encode(messages, normalize_embeddings=True)"
   ],
   "id": "5b3d4870b1cd3a44",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:34:18.515897Z",
     "start_time": "2024-06-19T19:34:18.499946Z"
    }
   },
   "cell_type": "code",
   "source": "# print(get_embeddings_open_source(\"Hello, how are you?\", embedding_model))",
   "id": "970cf5fad7fa9093",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:34:19.539319Z",
     "start_time": "2024-06-19T19:34:19.533582Z"
    }
   },
   "cell_type": "code",
   "source": "# print(len(get_embeddings_open_source(\"Hello, how are you?\", embedding_model)))",
   "id": "4c826fb594b7877c",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:34:19.718603Z",
     "start_time": "2024-06-19T19:34:19.711525Z"
    }
   },
   "cell_type": "code",
   "source": "# print(get_embeddings(message=\"Hello, how are you?\"))",
   "id": "4feb10ffd2c8d4c6",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:34:20.402701Z",
     "start_time": "2024-06-19T19:34:20.399518Z"
    }
   },
   "cell_type": "code",
   "source": "# print(len(get_embeddings(message=\"Hello, how are you?\")))",
   "id": "d25bc50853512e8e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:37:18.508833Z",
     "start_time": "2024-06-19T19:37:18.477900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_embeddings_to_pinecone_open_source(chat_history: List[str],\n",
    "                                           pinecone_index_name: Optional[str] = 'opensource-embeddings'):\n",
    "    \"\"\"\n",
    "    Add embeddings to Pinecone index using an open-source text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    chat_history (List[str]): The chat history to be added to the Pinecone index.\n",
    "    pinecone_index_name (str, optional): The name of the Pinecone index. Defaults to 'chat-history-open-source'.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified Pinecone index does not exist.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone index\n",
    "        pinecone_index = initialize_pinecone_index(pinecone_index_name)\n",
    "        if pinecone_index is None:\n",
    "            raise ValueError(f\"Index {pinecone_index_name} does not exist.\")\n",
    "\n",
    "        embeddings = []\n",
    "        for i, message in enumerate(chat_history):\n",
    "            embedding = get_embeddings_open_source(message, embedding_model)\n",
    "            embeddings.append({\n",
    "                'id': str(i + 1),\n",
    "                'values': embedding.tolist(),\n",
    "                'metadata': {'text': message}\n",
    "            })\n",
    "        pinecone_index.upsert(vectors=embeddings)\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"Finished processing embeddings.\")"
   ],
   "id": "9326bcbdb711e03",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:37:37.147099Z",
     "start_time": "2024-06-19T19:37:19.127573Z"
    }
   },
   "cell_type": "code",
   "source": "add_embeddings_to_pinecone_open_source(history)",
   "id": "22db4a68d944a3ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing Pinecone index.\n",
      "[ 0.06640825 -0.00498162 -0.03351139 ... -0.00099763 -0.02269631\n",
      " -0.04536788]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03010496  0.00481044  0.00705468 ... -0.04326796 -0.03929177\n",
      " -0.03224383]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.04942119  0.00351219 -0.01418415 ... -0.01627847  0.00035702\n",
      " -0.02105516]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.01347936  0.01195142 -0.04309826 ... -0.00621914  0.0069764\n",
      " -0.03176572]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03412233  0.00378344 -0.04075072 ... -0.02442858  0.01617874\n",
      " -0.01458771]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.04094969 -0.00814151 -0.02709641 ... -0.03023439  0.0178825\n",
      " -0.02095387]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.04217416  0.03770748 -0.00560683 ...  0.01342603  0.00257149\n",
      " -0.02553049]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03823996  0.04391637 -0.00206581 ...  0.03683512  0.02549322\n",
      " -0.00244387]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.01962451 -0.02173681 -0.00331002 ...  0.01590492  0.00102395\n",
      "  0.00025747]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03514722 -0.01321477 -0.012081   ... -0.00782442 -0.01463844\n",
      " -0.03042761]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.05988127 -0.00256801 -0.01983659 ... -0.03369965  0.00526709\n",
      " -0.02040873]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.02847348 -0.00775723 -0.02821252 ... -0.03421802 -0.03002582\n",
      " -0.01574719]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.05757451 -0.00430455  0.00897803 ...  0.01240531 -0.00677897\n",
      " -0.04312738]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.05234042 -0.00542395  0.00773524 ... -0.01414665 -0.01152518\n",
      " -0.00602636]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.0545202  -0.01714157  0.00179299 ... -0.00222233 -0.03694241\n",
      " -0.0241973 ]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.05090221 -0.00120736 -0.04209825 ... -0.00105805 -0.01413559\n",
      "  0.01859491]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.04863886 -0.0058365  -0.01725563 ... -0.02096415  0.02094445\n",
      " -0.00232912]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03922841 -0.01477639 -0.01024176 ... -0.04906992  0.01707985\n",
      " -0.00569409]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.03801211 -0.0067269  -0.01577943 ... -0.00993733  0.0242\n",
      " -0.03335596]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.05268858  0.0025082  -0.02636867 ... -0.02180661  0.01718009\n",
      " -0.02531847]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Finished processing embeddings.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:40:38.878854Z",
     "start_time": "2024-06-19T19:40:38.819997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_relevant_history_open_source(query: str, top_k: Optional[int] = 2,\n",
    "                                          pinecone_index_name: Optional[str] = 'opensource-embeddings'):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant message from the chat history based on the query using an open-source text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The query to be used for searching the chat history.\n",
    "    top_k (int, optional): The number of most relevant messages to retrieve. Defaults to 2.\n",
    "    pinecone_index_name (str, optional): The name of the Pinecone index. Defaults to 'chat-history-open-source'.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the specified Pinecone index does not exist.\n",
    "\n",
    "    Returns:\n",
    "    str: The most relevant message from the chat history.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone index\n",
    "        pinecone_index = initialize_pinecone_index(pinecone_index_name)\n",
    "        if pinecone_index is None:\n",
    "            raise ValueError(f\"Index {pinecone_index_name} does not exist.\")\n",
    "\n",
    "        # Get embeddings for the query\n",
    "        query_embedding = get_embeddings_open_source(query, embedding_model)\n",
    "\n",
    "        # Search for the most relevant message in the chat history\n",
    "        search_results = pinecone_index.query(vector=[query_embedding.tolist()], top_k=top_k,\n",
    "                                              include_metadata=True)\n",
    "\n",
    "        # Get the most relevant message [top 2] based on the similarity score\n",
    "        relevant_message = '\\n'.join([r['metadata']['text'] for r in search_results['matches']])\n",
    "\n",
    "        return relevant_message\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        print(\"Finished retrieving relevant history.\")"
   ],
   "id": "e096dde79ddbda0a",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:40:39.157690Z",
     "start_time": "2024-06-19T19:40:39.139744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_system_prompt_open_source(query: str):\n",
    "    \"\"\"\n",
    "    Prepare the prompt for the OpenAI chat completion API using an open-source text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user query.\n",
    "\n",
    "    Returns:\n",
    "    str: The prepared prompt.\n",
    "    str: The context referred to in the prompt.\n",
    "    \"\"\"\n",
    "    # Retrieve the most relevant chat history based on the user's query\n",
    "    context = retrieve_relevant_history_open_source(query)\n",
    "\n",
    "    # Prepare the prompt template\n",
    "    prompt_template = (\"You are an AI assistant named Viamagus. \"\n",
    "                       \"Your role is to assist the user by answering their queries based on the context provided. \"\n",
    "                       \"You have access to the following context:\\n\"\n",
    "                       f\"{context}\\n\"\n",
    "                       )\n",
    "\n",
    "    return prompt_template, context"
   ],
   "id": "79f132f819e13fb9",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:40:39.563853Z",
     "start_time": "2024-06-19T19:40:39.553831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_with_openai_open_source(query: str):\n",
    "    \"\"\"\n",
    "    Chat with the OpenAI chat completion API using an open-source text-embedding model.\n",
    "\n",
    "    Parameters:\n",
    "    query (str): The user query.\n",
    "\n",
    "    Returns:\n",
    "    str: The response from the OpenAI chat completion API.\n",
    "    str: The context referred to in the response.\n",
    "    \"\"\"\n",
    "    system_prompt, context_referred = prepare_system_prompt_open_source(query)\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=TEMPERATURE\n",
    "    )\n",
    "    return res.choices[0].message.content, context_referred"
   ],
   "id": "1040ce2cdf29424f",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:42:22.410903Z",
     "start_time": "2024-06-19T19:42:22.400633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_final_prompt_open_source():\n",
    "    query = \"Do you think it will help me stay fit?\"\n",
    "    response, context = chat_with_openai_open_source(query)\n",
    "    print(f\"\\nFinal Test Prompt: \\n{query}\\n\")\n",
    "    print(f\"Context Referred: \\n{context}\\n\")\n",
    "    print(f\"Final Test Prompt Response: \\n{response}\\n\")"
   ],
   "id": "c53363ec240a6502",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T19:42:28.033903Z",
     "start_time": "2024-06-19T19:42:22.617328Z"
    }
   },
   "cell_type": "code",
   "source": "test_final_prompt_open_source()",
   "id": "b1efd08642f074af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing Pinecone index.\n",
      "Finished retrieving relevant history.\n",
      "\n",
      "Final Test Prompt: \n",
      "Do you think it will help me stay fit?\n",
      "\n",
      "Context Referred: \n",
      "7: User: Perfect! Now, what are some good exercises? | Bot: You can try a mix of cardio and strength training exercises.\n",
      "8: User: Any specific recommendations for cardio? | Bot: Running, cycling, and swimming are all excellent cardio exercises.\n",
      "9: User: I'll start with running. Can you recommend any books? | Bot: 'Atomic Habits' by James Clear is a highly recommended book.\n",
      "\n",
      "Final Test Prompt Response: \n",
      "Yes, 'Atomic Habits' by James Clear can be very helpful in staying fit. The book focuses on building good habits and breaking bad ones, which can be critical in maintaining a consistent fitness routine. By applying the principles outlined in the book, you can create sustainable habits that support your fitness goals, such as regular running and other exercises.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6349e80d27b3cda2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
